{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91708657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af00f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(page_number):\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "    }\n",
    "    url = f'https://kolesa.kz/cars/toyota/?page={page_number}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        return soup\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12a5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "# number_of_pages = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing page 200...\n",
      "Parsing page 201...\n",
      "Parsing page 202...\n",
      "Parsing page 203...\n",
      "Parsing page 204...\n",
      "Parsing page 205...\n",
      "Parsing page 206...\n",
      "Parsing page 207...\n",
      "Parsing page 208...\n",
      "Parsing page 209...\n",
      "Parsing page 210...\n",
      "Parsing page 211...\n",
      "Parsing page 212...\n",
      "Parsing page 213...\n",
      "Parsing page 214...\n",
      "Parsing page 215...\n",
      "Parsing page 216...\n",
      "Parsing page 217...\n",
      "Parsing page 218...\n",
      "Parsing page 219...\n",
      "Parsing page 220...\n",
      "Parsing page 221...\n",
      "Parsing page 222...\n",
      "Parsing page 223...\n",
      "Parsing page 224...\n",
      "Parsing page 225...\n",
      "Parsing page 226...\n",
      "Parsing page 227...\n",
      "Parsing page 228...\n",
      "Parsing page 229...\n",
      "Parsing page 230...\n",
      "Parsing page 231...\n",
      "Parsing page 232...\n",
      "Parsing page 233...\n",
      "Parsing page 234...\n",
      "Parsing page 235...\n",
      "Parsing page 236...\n",
      "Parsing page 237...\n",
      "Parsing page 238...\n",
      "Parsing page 239...\n",
      "Parsing page 240...\n",
      "Parsing page 241...\n",
      "Parsing page 242...\n",
      "Parsing page 243...\n",
      "Parsing page 244...\n",
      "Parsing page 245...\n",
      "Parsing page 246...\n",
      "Parsing page 247...\n",
      "Parsing page 248...\n",
      "Parsing page 249...\n",
      "Parsing page 250...\n",
      "Parsing page 251...\n",
      "Parsing page 252...\n",
      "Parsing page 253...\n",
      "Parsing page 254...\n",
      "Parsing page 255...\n",
      "Parsing page 256...\n",
      "Parsing page 257...\n",
      "Parsing page 258...\n",
      "Parsing page 259...\n",
      "Parsing page 260...\n",
      "Parsing page 261...\n",
      "Parsing page 262...\n",
      "Parsing page 263...\n",
      "Parsing page 264...\n",
      "Parsing page 265...\n",
      "Parsing page 266...\n",
      "Parsing page 267...\n",
      "Parsing page 268...\n",
      "Parsing page 269...\n",
      "Parsing page 270...\n",
      "Parsing page 271...\n",
      "Parsing page 272...\n",
      "Parsing page 273...\n",
      "Parsing page 274...\n",
      "Parsing page 275...\n",
      "Parsing page 276...\n",
      "Parsing page 277...\n",
      "Parsing page 278...\n",
      "Parsing page 279...\n",
      "Parsing page 280...\n",
      "Parsing page 281...\n",
      "Parsing page 282...\n",
      "Parsing page 283...\n",
      "Parsing page 284...\n",
      "Parsing page 285...\n",
      "Parsing page 286...\n",
      "Parsing page 287...\n",
      "Parsing page 288...\n",
      "Parsing page 289...\n",
      "Parsing page 290...\n",
      "Parsing page 291...\n",
      "Parsing page 292...\n",
      "Parsing page 293...\n",
      "Parsing page 294...\n",
      "Parsing page 295...\n",
      "Parsing page 296...\n",
      "Parsing page 297...\n",
      "Parsing page 298...\n",
      "Parsing page 299...\n",
      "Parsing page 300...\n"
     ]
    }
   ],
   "source": [
    "for i in range(200, 301):\n",
    "    print(f\"Parsing page {i}...\")\n",
    "    \n",
    "    soup = scrap(i)\n",
    "    \n",
    "    if soup is None:\n",
    "        print(f\"Error on page {i} or page not found.\")\n",
    "        continue\n",
    "\n",
    "    links = soup.find_all('a', class_='a-card__link')\n",
    "\n",
    "    for link in links:\n",
    "        title = link.text.strip()\n",
    "\n",
    "        card = link.find_parent('div', class_='a-card')\n",
    "\n",
    "        if card:\n",
    "            price_tag = card.find('span', class_='a-card__price')\n",
    "            price = price_tag.text.strip().replace('\\xa0', ' ') if price_tag else None\n",
    "\n",
    "            desc_tag = card.find('p', class_='a-card__description')\n",
    "            description = desc_tag.text.strip() if desc_tag else None\n",
    "\n",
    "\n",
    "            data.append({\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'description': description\n",
    "            })\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f79a0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.loc[df['title'] != \"\"]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc0736ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df['description'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5a22065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = splits[0].str.replace('г.', '').str.strip()\n",
    "df['body_type'] = splits[1].str.strip()\n",
    "df['volume'] = splits[2].str.replace('л', '').str.strip()\n",
    "df['fuel'] = splits[3].str.strip()\n",
    "df['gearbox'] = splits[4].str.replace('КПП', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c25441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['description'])\n",
    "splits = df['body_type'].str.split(' ', expand=True)\n",
    "df['type'] = splits[0]\n",
    "df['body_type'] = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0988326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2020, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3beed40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('kolesa_cars3.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
